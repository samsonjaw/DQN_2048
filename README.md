# 2048 Reinforcement Learning Agent using Deep Q-Learning
This project implements a reinforcement learning agent based on Deep Q-Learning (DQN) to play the game 2048. The agent learns to make decisions on how to move tiles in order to maximize its score in the game.
(2048 environment created by myself)

## process
I have gone through many revisions. Different folders represent different versions.

## Features
- **2048 enviroment**: Implement the 2048 game environment using Pygame, with the option to toggle visualization.
  In environment_2048.py, you can find below code:
```python
class game_2048():
    def __init__(self):
        self.score = 0
        self.highest_block = 0
        self.width, self.height = (370, 600)
        self.margin_size = 10
        self.block_size = 80
        self.show_screen = 0
        self.max_illegal_move = 100     # max number of illegal actions
        self.num_illegal_move = 0
        self.increased_epsilon_countdown = 0
```
  set self.show_screen = 1 can toggle visualization

- **Deep Q-Learning**: Implement to tensorflow to implement Deep Q-Learning.
- **FC+CNN**: Use Fully Connected Layer and Convolurional Neural Layer to build a neural network.
### strategy
- **Delayed updating of the target network**: The parameters of the target network are updated less frequently compared to the online network.This strategy helps stabilize the training process.
- **Epsilon-Greedy**:A simple method to balance exploration and exploitation by choosing between exploration and exploitation randomly. The epsilon will decrease when episode increase.
- **Replay buffer**: It stores experiences generated by the agent interacting with the environment. These experiences accumulate in the buffer over time and can be sampled for training.
- **Prioritized Experience Replay(PER)**: Experiences stored in the replay buffer are assigned priorities based on their estimated importance or potential for learning. When sampling experiences, the agent can focus on significant experiences.
- **Double Deep Q-Learning(DDQN)**: In traditional DQN, the same network(evalutation-network) is used to both choose and evaluate actions, which can lead to overestimation of Q-values.**In DDQN**, it use evaluation-network to choose action and use targer-network to calculate the Q-values.

## Project Structure
- **run.py**: Main script to run the 2048 game and train the reinforcement learning agent.
- **RL_brain.py**: Implementation of the Deep Q-Learning algorithm.
- **environment_2048.py**: Environment for the 2048 game, including game mechanics and graphical interface using Pygame.
- **SumTree.py**: Implementation of the SumTree data structure for prioritized experience replay.
- **tb.py**: Logging module for TensorBoard visualization.

## tensorboard
1.To launch TensorBoard and visualize the logs, you can use the following command in your terminal:
```bash
tensorboard --logdir=logs
```
2. go http://localhost:6006
   
## network save
After training, the trained model weights will be saved in the net/ directory. You can use these weights to evaluate the agent's performance or deploy it in a real game environment.



## Contributing
Contributions are welcome!

You can help by:

- Reporting issues
- Suggesting improvements
- Adding new features through pull requests

## License
This project is licensed under the MIT License.


